{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('input/train.csv')\n",
    "test_df = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_df = train_df.sample(frac=0.7, random_state=2011, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['ID_code', 'target'], axis=1)\n",
    "y = train_df['target']\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(['ID_code'], axis=1)\n",
    "X_test_IDs = test_df['ID_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "transformed = pd.DataFrame(QuantileTransformer(output_distribution='normal').fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pipeline = make_pipeline(QuantileTransformer(output_distribution='normal'), GaussianNB())\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': np.arange(2,40,5), \n",
    "         'objective':'binary',\n",
    "         'max_depth': [2, 5, 7, 10, 13, -1],\n",
    "         'learning_rate': 10**((np.random.random(10)-1)*2.5),\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": ['gbdt', 'gbrt', 'random_forest'],\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\":[0.7, 0.8, 0.9, 0.95],\n",
    "         \"bagging_seed\": 11,\n",
    "         \"feature_fraction\":[0.7, 0.8, 0.9, 0.95], \n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 10**((.5*np.random.random(10)-1)*3),\n",
    "         \"lambda_l2\": 10**((.5*np.random.random(10)-1)*3),\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": -1,\n",
    "         \"random_state\": 1992}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parms(params_dict):\n",
    "    dict_ = {}\n",
    "    for param, value in params_dict.items():\n",
    "        if isinstance(value, list) or isinstance(value, np.ndarray): \n",
    "            dict_[param] = np.random.choice(value, 1)[0]\n",
    "        else:\n",
    "            dict_[param] = value\n",
    "            \n",
    "    return dict_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_df = train_df.sample(50000)\n",
    "small_X = small_train_df.drop(['ID_code', 'target'], axis=1)\n",
    "small_y = small_train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_predictions = np.zeros(y.shape)\n",
    "test_predictions = np.zeros(X_test_IDs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "best_score = 0.\n",
    "for i in range(50):\n",
    "    print(\"------------ training the {} th model -------------\".format(i))\n",
    "    param = get_parms(params)\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(small_X, small_y.values)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(small_X.iloc[trn_idx,:], label=small_y.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(small_X.iloc[val_idx,:], label=small_y.iloc[val_idx])\n",
    "\n",
    "        num_round = 20000\n",
    "        clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=300, early_stopping_rounds=200)\n",
    "        oof_predictions[val_idx] = clf.predict(small_X.iloc[val_idx,:], num_iteration=clf.best_iteration)\n",
    "    score = roc_auc_score(small_y, oof_predictions)\n",
    "    print('----------------- auc score == {} -------------------'.format(score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = param\n",
    "    scores.append((score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.838027\tvalid_1's auc: 0.805029\n",
      "[600]\ttraining's auc: 0.87684\tvalid_1's auc: 0.83491\n",
      "[900]\ttraining's auc: 0.898092\tvalid_1's auc: 0.850715\n",
      "[1200]\ttraining's auc: 0.912177\tvalid_1's auc: 0.860903\n",
      "[1500]\ttraining's auc: 0.922454\tvalid_1's auc: 0.868016\n",
      "[1800]\ttraining's auc: 0.930385\tvalid_1's auc: 0.87338\n",
      "[2100]\ttraining's auc: 0.936786\tvalid_1's auc: 0.877525\n",
      "[2400]\ttraining's auc: 0.942032\tvalid_1's auc: 0.880677\n",
      "[2700]\ttraining's auc: 0.946608\tvalid_1's auc: 0.883314\n",
      "[3000]\ttraining's auc: 0.95068\tvalid_1's auc: 0.885497\n",
      "[3300]\ttraining's auc: 0.954236\tvalid_1's auc: 0.887297\n",
      "[3600]\ttraining's auc: 0.957469\tvalid_1's auc: 0.888705\n",
      "[3900]\ttraining's auc: 0.960335\tvalid_1's auc: 0.889867\n",
      "[4200]\ttraining's auc: 0.96297\tvalid_1's auc: 0.890711\n",
      "[4500]\ttraining's auc: 0.965422\tvalid_1's auc: 0.891601\n",
      "[4800]\ttraining's auc: 0.967738\tvalid_1's auc: 0.892288\n",
      "[5100]\ttraining's auc: 0.969917\tvalid_1's auc: 0.892891\n",
      "[5400]\ttraining's auc: 0.971969\tvalid_1's auc: 0.893421\n",
      "[5700]\ttraining's auc: 0.973911\tvalid_1's auc: 0.893864\n",
      "[6000]\ttraining's auc: 0.975783\tvalid_1's auc: 0.894229\n",
      "[6300]\ttraining's auc: 0.977532\tvalid_1's auc: 0.894545\n",
      "[6600]\ttraining's auc: 0.97918\tvalid_1's auc: 0.894821\n",
      "[6900]\ttraining's auc: 0.980802\tvalid_1's auc: 0.894967\n",
      "[7200]\ttraining's auc: 0.982342\tvalid_1's auc: 0.895093\n",
      "[7500]\ttraining's auc: 0.983749\tvalid_1's auc: 0.895168\n",
      "[7800]\ttraining's auc: 0.985107\tvalid_1's auc: 0.895213\n",
      "[8100]\ttraining's auc: 0.98634\tvalid_1's auc: 0.895269\n",
      "[8400]\ttraining's auc: 0.987499\tvalid_1's auc: 0.895317\n",
      "[8700]\ttraining's auc: 0.988579\tvalid_1's auc: 0.895419\n",
      "Early stopping, best iteration is:\n",
      "[8795]\ttraining's auc: 0.9889\tvalid_1's auc: 0.895449\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.836109\tvalid_1's auc: 0.798247\n",
      "[600]\ttraining's auc: 0.875725\tvalid_1's auc: 0.831278\n",
      "[900]\ttraining's auc: 0.897024\tvalid_1's auc: 0.848678\n",
      "[1200]\ttraining's auc: 0.910768\tvalid_1's auc: 0.859866\n",
      "[1500]\ttraining's auc: 0.921112\tvalid_1's auc: 0.867583\n",
      "[1800]\ttraining's auc: 0.929217\tvalid_1's auc: 0.873388\n",
      "[2100]\ttraining's auc: 0.935719\tvalid_1's auc: 0.877662\n",
      "[2400]\ttraining's auc: 0.941086\tvalid_1's auc: 0.881058\n",
      "[2700]\ttraining's auc: 0.945817\tvalid_1's auc: 0.883833\n",
      "[3000]\ttraining's auc: 0.949844\tvalid_1's auc: 0.885986\n",
      "[3300]\ttraining's auc: 0.953467\tvalid_1's auc: 0.887812\n",
      "[3600]\ttraining's auc: 0.956765\tvalid_1's auc: 0.889387\n",
      "[3900]\ttraining's auc: 0.959771\tvalid_1's auc: 0.890607\n",
      "[4200]\ttraining's auc: 0.9625\tvalid_1's auc: 0.891676\n",
      "[4500]\ttraining's auc: 0.965008\tvalid_1's auc: 0.892661\n",
      "[4800]\ttraining's auc: 0.96736\tvalid_1's auc: 0.893405\n",
      "[5100]\ttraining's auc: 0.969602\tvalid_1's auc: 0.894072\n",
      "[5400]\ttraining's auc: 0.97171\tvalid_1's auc: 0.894575\n",
      "[5700]\ttraining's auc: 0.973697\tvalid_1's auc: 0.895043\n",
      "[6000]\ttraining's auc: 0.975582\tvalid_1's auc: 0.895419\n",
      "[6300]\ttraining's auc: 0.977387\tvalid_1's auc: 0.895755\n",
      "[6600]\ttraining's auc: 0.979103\tvalid_1's auc: 0.895997\n",
      "[6900]\ttraining's auc: 0.980747\tvalid_1's auc: 0.896167\n",
      "[7200]\ttraining's auc: 0.982227\tvalid_1's auc: 0.896378\n",
      "[7500]\ttraining's auc: 0.983671\tvalid_1's auc: 0.896524\n",
      "[7800]\ttraining's auc: 0.984998\tvalid_1's auc: 0.896627\n",
      "[8100]\ttraining's auc: 0.986224\tvalid_1's auc: 0.896744\n",
      "[8400]\ttraining's auc: 0.987391\tvalid_1's auc: 0.896779\n",
      "[8700]\ttraining's auc: 0.988485\tvalid_1's auc: 0.896853\n",
      "[9000]\ttraining's auc: 0.989483\tvalid_1's auc: 0.896917\n",
      "[9300]\ttraining's auc: 0.990414\tvalid_1's auc: 0.89701\n",
      "[9600]\ttraining's auc: 0.991261\tvalid_1's auc: 0.897041\n",
      "[9900]\ttraining's auc: 0.992017\tvalid_1's auc: 0.897064\n",
      "[10200]\ttraining's auc: 0.992728\tvalid_1's auc: 0.897091\n",
      "[10500]\ttraining's auc: 0.993383\tvalid_1's auc: 0.897166\n",
      "[10800]\ttraining's auc: 0.993985\tvalid_1's auc: 0.897178\n",
      "Early stopping, best iteration is:\n",
      "[10894]\ttraining's auc: 0.994155\tvalid_1's auc: 0.897203\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.836558\tvalid_1's auc: 0.805723\n",
      "[600]\ttraining's auc: 0.875044\tvalid_1's auc: 0.837605\n",
      "[900]\ttraining's auc: 0.89646\tvalid_1's auc: 0.854488\n",
      "[1200]\ttraining's auc: 0.910739\tvalid_1's auc: 0.864466\n",
      "[1500]\ttraining's auc: 0.921202\tvalid_1's auc: 0.871748\n",
      "[1800]\ttraining's auc: 0.929339\tvalid_1's auc: 0.877012\n",
      "[2100]\ttraining's auc: 0.935964\tvalid_1's auc: 0.881014\n",
      "[2400]\ttraining's auc: 0.941451\tvalid_1's auc: 0.884159\n",
      "[2700]\ttraining's auc: 0.946198\tvalid_1's auc: 0.886625\n",
      "[3000]\ttraining's auc: 0.950299\tvalid_1's auc: 0.888654\n",
      "[3300]\ttraining's auc: 0.95396\tvalid_1's auc: 0.890272\n",
      "[3600]\ttraining's auc: 0.957272\tvalid_1's auc: 0.891652\n",
      "[3900]\ttraining's auc: 0.960221\tvalid_1's auc: 0.892746\n",
      "[4200]\ttraining's auc: 0.962928\tvalid_1's auc: 0.893624\n",
      "[4500]\ttraining's auc: 0.965456\tvalid_1's auc: 0.894424\n",
      "[4800]\ttraining's auc: 0.967793\tvalid_1's auc: 0.895144\n",
      "[5100]\ttraining's auc: 0.96997\tvalid_1's auc: 0.89568\n",
      "[5400]\ttraining's auc: 0.971997\tvalid_1's auc: 0.896085\n",
      "[5700]\ttraining's auc: 0.973927\tvalid_1's auc: 0.89644\n",
      "[6000]\ttraining's auc: 0.975816\tvalid_1's auc: 0.896763\n",
      "[6300]\ttraining's auc: 0.977562\tvalid_1's auc: 0.897055\n",
      "[6600]\ttraining's auc: 0.979285\tvalid_1's auc: 0.897281\n",
      "[6900]\ttraining's auc: 0.980915\tvalid_1's auc: 0.897428\n",
      "[7200]\ttraining's auc: 0.982418\tvalid_1's auc: 0.897543\n",
      "[7500]\ttraining's auc: 0.983854\tvalid_1's auc: 0.89766\n",
      "[7800]\ttraining's auc: 0.985207\tvalid_1's auc: 0.897746\n",
      "[8100]\ttraining's auc: 0.986437\tvalid_1's auc: 0.897752\n",
      "[8400]\ttraining's auc: 0.987573\tvalid_1's auc: 0.897765\n",
      "Early stopping, best iteration is:\n",
      "[8294]\ttraining's auc: 0.98717\tvalid_1's auc: 0.89779\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.838052\tvalid_1's auc: 0.802734\n",
      "[600]\ttraining's auc: 0.875834\tvalid_1's auc: 0.833342\n",
      "[900]\ttraining's auc: 0.896998\tvalid_1's auc: 0.849543\n",
      "[1200]\ttraining's auc: 0.911225\tvalid_1's auc: 0.860119\n",
      "[1500]\ttraining's auc: 0.921651\tvalid_1's auc: 0.867404\n",
      "[1800]\ttraining's auc: 0.929809\tvalid_1's auc: 0.872554\n",
      "[2100]\ttraining's auc: 0.936394\tvalid_1's auc: 0.87662\n",
      "[2400]\ttraining's auc: 0.941829\tvalid_1's auc: 0.879825\n",
      "[2700]\ttraining's auc: 0.946537\tvalid_1's auc: 0.882294\n",
      "[3000]\ttraining's auc: 0.950588\tvalid_1's auc: 0.884289\n",
      "[3300]\ttraining's auc: 0.954207\tvalid_1's auc: 0.885916\n",
      "[3600]\ttraining's auc: 0.95744\tvalid_1's auc: 0.887356\n",
      "[3900]\ttraining's auc: 0.960344\tvalid_1's auc: 0.88856\n",
      "[4200]\ttraining's auc: 0.963005\tvalid_1's auc: 0.889492\n",
      "[4500]\ttraining's auc: 0.965482\tvalid_1's auc: 0.890288\n",
      "[4800]\ttraining's auc: 0.967841\tvalid_1's auc: 0.891064\n",
      "[5100]\ttraining's auc: 0.970047\tvalid_1's auc: 0.891646\n",
      "[5400]\ttraining's auc: 0.972059\tvalid_1's auc: 0.892093\n",
      "[5700]\ttraining's auc: 0.974012\tvalid_1's auc: 0.892495\n",
      "[6000]\ttraining's auc: 0.975915\tvalid_1's auc: 0.892781\n",
      "[6300]\ttraining's auc: 0.977688\tvalid_1's auc: 0.892942\n",
      "[6600]\ttraining's auc: 0.979371\tvalid_1's auc: 0.893127\n",
      "[6900]\ttraining's auc: 0.980943\tvalid_1's auc: 0.893295\n",
      "[7200]\ttraining's auc: 0.982461\tvalid_1's auc: 0.893438\n",
      "[7500]\ttraining's auc: 0.983873\tvalid_1's auc: 0.893498\n",
      "[7800]\ttraining's auc: 0.985209\tvalid_1's auc: 0.893534\n",
      "[8100]\ttraining's auc: 0.986441\tvalid_1's auc: 0.893624\n",
      "[8400]\ttraining's auc: 0.987619\tvalid_1's auc: 0.893688\n",
      "[8700]\ttraining's auc: 0.988686\tvalid_1's auc: 0.89376\n",
      "[9000]\ttraining's auc: 0.989667\tvalid_1's auc: 0.893826\n",
      "Early stopping, best iteration is:\n",
      "[9057]\ttraining's auc: 0.989842\tvalid_1's auc: 0.893843\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.837216\tvalid_1's auc: 0.804817\n",
      "[600]\ttraining's auc: 0.875833\tvalid_1's auc: 0.836491\n",
      "[900]\ttraining's auc: 0.896872\tvalid_1's auc: 0.85243\n",
      "[1200]\ttraining's auc: 0.910894\tvalid_1's auc: 0.862893\n",
      "[1500]\ttraining's auc: 0.921197\tvalid_1's auc: 0.870178\n",
      "[1800]\ttraining's auc: 0.929231\tvalid_1's auc: 0.875553\n",
      "[2100]\ttraining's auc: 0.935815\tvalid_1's auc: 0.879633\n",
      "[2400]\ttraining's auc: 0.941246\tvalid_1's auc: 0.882806\n",
      "[2700]\ttraining's auc: 0.945862\tvalid_1's auc: 0.88539\n",
      "[3000]\ttraining's auc: 0.950008\tvalid_1's auc: 0.887637\n",
      "[3300]\ttraining's auc: 0.95355\tvalid_1's auc: 0.889425\n",
      "[3600]\ttraining's auc: 0.956778\tvalid_1's auc: 0.890976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3900]\ttraining's auc: 0.959708\tvalid_1's auc: 0.892172\n",
      "[4200]\ttraining's auc: 0.962354\tvalid_1's auc: 0.893215\n",
      "[4500]\ttraining's auc: 0.964864\tvalid_1's auc: 0.894168\n",
      "[4800]\ttraining's auc: 0.967242\tvalid_1's auc: 0.894914\n",
      "[5100]\ttraining's auc: 0.969408\tvalid_1's auc: 0.895539\n",
      "[5400]\ttraining's auc: 0.971454\tvalid_1's auc: 0.896142\n",
      "[5700]\ttraining's auc: 0.973451\tvalid_1's auc: 0.896618\n",
      "[6000]\ttraining's auc: 0.975335\tvalid_1's auc: 0.896958\n",
      "[6300]\ttraining's auc: 0.977127\tvalid_1's auc: 0.89727\n",
      "[6600]\ttraining's auc: 0.978873\tvalid_1's auc: 0.897469\n",
      "[6900]\ttraining's auc: 0.980486\tvalid_1's auc: 0.897692\n",
      "[7200]\ttraining's auc: 0.982019\tvalid_1's auc: 0.89786\n",
      "[7500]\ttraining's auc: 0.983465\tvalid_1's auc: 0.89807\n",
      "[7800]\ttraining's auc: 0.984796\tvalid_1's auc: 0.89814\n",
      "[8100]\ttraining's auc: 0.986028\tvalid_1's auc: 0.898263\n",
      "[8400]\ttraining's auc: 0.987206\tvalid_1's auc: 0.898347\n",
      "[8700]\ttraining's auc: 0.988284\tvalid_1's auc: 0.898413\n",
      "[9000]\ttraining's auc: 0.989285\tvalid_1's auc: 0.898412\n",
      "Early stopping, best iteration is:\n",
      "[9098]\ttraining's auc: 0.989596\tvalid_1's auc: 0.898437\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.05,\n",
    "         \"min_child_samples\": 20,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": 4,\n",
    "         \"random_state\": 2019}\n",
    "\n",
    "param = {'num_leaves': 31,\n",
    "   'min_data_in_leaf': 12,\n",
    "   'objective': 'binary',\n",
    "   'max_depth': 13,\n",
    "   'learning_rate': 0.0053688798975117845,\n",
    "   'min_child_samples': 20,\n",
    "   'boosting': 'gbdt',\n",
    "   'bagging_freq': 1,\n",
    "   'bagging_fraction': 0.9,\n",
    "   'bagging_seed': 11,\n",
    "   'feature_fraction': 0.8,\n",
    "   'metric': 'auc',\n",
    "   'lambda_l1': 0.00027574321473024596,\n",
    "   'lambda_l2': 0.22104802305840615,\n",
    "   'verbosity': -1,\n",
    "   'nthread': -1,\n",
    "   'random_state': 1992}\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y.values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X.iloc[trn_idx,:], label=y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X.iloc[val_idx,:], label=y.iloc[val_idx])\n",
    "\n",
    "    num_round = 20000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=300, early_stopping_rounds=200)\n",
    "    oof_predictions[val_idx] = clf.predict(X.iloc[val_idx,:], num_iteration=clf.best_iteration)\n",
    "\n",
    "    \n",
    "    test_predictions += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y, oof_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = test_predictions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.clip(0, 1).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=7, n_jobs=-1, random_state=123, verbose=1, class_weight={1: .9, 0: .1})\n",
    "rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, quantile_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = quantile_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=7, n_jobs=-1, random_state=123, verbose=1, class_weight={1: .9, 0: .1})\n",
    "rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_valid==predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dist = {\n",
    "    'n_estimators':[10, 30, 50, 75, 100, 120],\n",
    "    'class_weight':[{1: 0.9, 0: 0.1}, {1: 0.99, 0: 0.01}, {1: 0.8, 0: 0.2}, {1: 0.95, 0: 0.05}],\n",
    "    'max_depth':[2, 3, 5, 7, 9, 11, 13, 15, 20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1, verbose=1)\n",
    "randomized_grid_search = RandomizedSearchCV(rfc, param_distributions=params_dist, n_iter=20,\n",
    "                                            scoring='precision', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = randomized_grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "quantile_scaler = quantile_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_preds = pd.read_csv('submission_naive_bayes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['ID_code'] = X_test_IDs\n",
    "submission_df['target'] = (predictions + naive_bayes_preds['target'].values)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_lgbm+naive_bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
