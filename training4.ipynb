{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name):\n",
    "    \n",
    "    model = lgb.LGBMClassifier(max_depth=-1,\n",
    "                               n_estimators=999999,\n",
    "                               learning_rate=0.02,\n",
    "                               colsample_bytree=0.3,\n",
    "                               num_leaves=2,\n",
    "                               metric='auc',\n",
    "                               objective='binary', \n",
    "                               n_jobs=8)\n",
    "     \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)],\n",
    "              verbose=0, \n",
    "              early_stopping_rounds=1000)\n",
    "                  \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save LightGBM Model\n",
    "    save_to = '{}{}_fold{}.txt'.format(lgb_path, name, counter+1)\n",
    "    model.booster_.save_model(save_to)\n",
    "    \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_xgb(X_fit, y_fit, X_val, y_val, counter, xgb_path, name):\n",
    "    \n",
    "    model = xgb.XGBClassifier(max_depth=2,\n",
    "                              n_estimators=999999,\n",
    "                              colsample_bytree=0.3,\n",
    "                              learning_rate=0.02,\n",
    "                              objective='binary:logistic', \n",
    "                              n_jobs=8)\n",
    "     \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "              verbose=0, \n",
    "              early_stopping_rounds=1000)\n",
    "              \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save XGBoost Model\n",
    "    save_to = '{}{}_fold{}.dat'.format(xgb_path, name, counter+1)\n",
    "    pickle.dump(model, open(save_to, \"wb\"))\n",
    "    \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cb(X_fit, y_fit, X_val, y_val, counter, cb_path, name):\n",
    "    \n",
    "    model = cb.CatBoostClassifier(iterations=999999,\n",
    "                                  max_depth=2,\n",
    "                                  learning_rate=0.02,\n",
    "                                  colsample_bylevel=0.03,\n",
    "                                  objective=\"Logloss\")\n",
    "                                  \n",
    "    model.fit(X_fit, y_fit, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "              verbose=0, early_stopping_rounds=1000)\n",
    "              \n",
    "    cv_val = model.predict_proba(X_val)[:,1]\n",
    "    \n",
    "    #Save Catboost Model          \n",
    "    save_to = \"{}{}_fold{}.mlmodel\".format(cb_path, name, counter+1)\n",
    "    model.save_model(save_to, format=\"coreml\", \n",
    "                     export_parameters={'prediction_type': 'probability'})\n",
    "                     \n",
    "    return cv_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage(df_path, lgb_path, xgb_path, cb_path):\n",
    "    \n",
    "    print('Load Train Data.')\n",
    "    df = pd.read_csv(df_path)\n",
    "    print('\\nShape of Train Data: {}'.format(df.shape))\n",
    "    \n",
    "    y_df = np.array(df['target'])                        \n",
    "    df_ids = np.array(df.index)                     \n",
    "    df.drop(['ID_code', 'target'], axis=1, inplace=True)\n",
    "    \n",
    "    lgb_cv_result = np.zeros(df.shape[0])\n",
    "    xgb_cv_result = np.zeros(df.shape[0])\n",
    "    cb_cv_result  = np.zeros(df.shape[0])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=101)\n",
    "    skf.get_n_splits(df_ids, y_df)\n",
    "    \n",
    "    print('\\nModel Fitting...')\n",
    "    for counter, ids in enumerate(skf.split(df_ids, y_df)):\n",
    "        print('\\nFold {}'.format(counter+1))\n",
    "        X_fit, y_fit = df.values[ids[0]], y_df[ids[0]]\n",
    "        X_val, y_val = df.values[ids[1]], y_df[ids[1]]\n",
    "    \n",
    "        print('LigthGBM')\n",
    "        lgb_cv_result[ids[1]] += fit_lgb(X_fit, y_fit, X_val, y_val, counter, lgb_path, name='lgb')\n",
    "        print('XGBoost')\n",
    "        xgb_cv_result[ids[1]] += fit_xgb(X_fit, y_fit, X_val, y_val, counter, xgb_path, name='xgb')\n",
    "        print('CatBoost')\n",
    "        cb_cv_result[ids[1]]  += fit_cb(X_fit,  y_fit, X_val, y_val, counter, cb_path,  name='cb')\n",
    "        \n",
    "        del X_fit, X_val, y_fit, y_val\n",
    "        gc.collect()\n",
    "    \n",
    "    auc_lgb  = round(roc_auc_score(y_df, lgb_cv_result),4)\n",
    "    auc_xgb  = round(roc_auc_score(y_df, xgb_cv_result),4)\n",
    "    auc_cb   = round(roc_auc_score(y_df, cb_cv_result), 4)\n",
    "    auc_mean = round(roc_auc_score(y_df, (lgb_cv_result+xgb_cv_result+cb_cv_result)/3), 4)\n",
    "    auc_mean_lgb_cb = round(roc_auc_score(y_df, (lgb_cv_result+cb_cv_result)/2), 4)\n",
    "    print('\\nLightGBM VAL AUC: {}'.format(auc_lgb))\n",
    "    print('XGBoost  VAL AUC: {}'.format(auc_xgb))\n",
    "    print('Catboost VAL AUC: {}'.format(auc_cb))\n",
    "    print('Mean Catboost+LightGBM VAL AUC: {}'.format(auc_mean_lgb_cb))\n",
    "    print('Mean XGBoost+Catboost+LightGBM, VAL AUC: {}\\n'.format(auc_mean))\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_stage(df_path, lgb_path, xgb_path, cb_path):\n",
    "    \n",
    "    print('Load Test Data.')\n",
    "    df = pd.read_csv(df_path)\n",
    "    print('\\nShape of Test Data: {}'.format(df.shape))\n",
    "    \n",
    "    df.drop(['ID_code'], axis=1, inplace=True)\n",
    "    \n",
    "    lgb_models = sorted(os.listdir(lgb_path))\n",
    "    xgb_models = sorted(os.listdir(xgb_path))\n",
    "    cb_models  = sorted(os.listdir(cb_path))\n",
    "    \n",
    "    lgb_result = np.zeros(df.shape[0])\n",
    "    xgb_result = np.zeros(df.shape[0])\n",
    "    cb_result  = np.zeros(df.shape[0])\n",
    "    \n",
    "    print('\\nMake predictions...\\n')\n",
    "    \n",
    "    print('With LightGBM...')\n",
    "    for m_name in lgb_models:\n",
    "        #Load LightGBM Model\n",
    "        model = lgb.Booster(model_file='{}{}'.format(lgb_path, m_name))\n",
    "        lgb_result += model.predict(df.values)\n",
    "     \n",
    "    print('With XGBoost...')    \n",
    "    for m_name in xgb_models:\n",
    "        #Load Catboost Model\n",
    "        model = pickle.load(open('{}{}'.format(xgb_path, m_name), \"rb\"))\n",
    "        xgb_result += model.predict(df.values)\n",
    "    \n",
    "    print('With CatBoost...')        \n",
    "    for m_name in cb_models:\n",
    "        #Load Catboost Model\n",
    "        model = cb.CatBoostClassifier()\n",
    "        model = model.load_model('{}{}'.format(cb_path, m_name), format = 'coreml')\n",
    "        cb_result += model.predict(df.values, prediction_type='Probability')[:,1]\n",
    "    \n",
    "    lgb_result /= len(lgb_models)\n",
    "    xgb_result /= len(xgb_models)\n",
    "    cb_result  /= len(cb_models)\n",
    "    \n",
    "    cb_result  /= len(cb_models)\n",
    "      \n",
    "    submission = pd.read_csv('./input/sample_submission.csv')\n",
    "    submission['target'] = (lgb_result+xgb_result+cb_result)/3\n",
    "    submission.to_csv('xgb_lgb_cb_starter_submission.csv', index=False)\n",
    "    submission['target'] = (lgb_result+cb_result)/2\n",
    "    submission.to_csv('lgb_cb_starter_submission.csv', index=False)\n",
    "    submission['target'] = xgb_result\n",
    "    submission.to_csv('xgb_starter_submission.csv', index=False)\n",
    "    submission['target'] = lgb_result\n",
    "    submission.to_csv('lgb_starter_submission.csv', index=False)\n",
    "    submission['target'] = cb_result\n",
    "    submission.to_csv('cb_starter_submission.csv', index=False)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Stage.\n",
      "\n",
      "Load Train Data.\n",
      "\n",
      "Shape of Train Data: (200000, 202)\n",
      "\n",
      "Model Fitting...\n",
      "\n",
      "Fold 1\n",
      "LigthGBM\n",
      "XGBoost\n",
      "CatBoost\n",
      "\n",
      "Fold 2\n",
      "LigthGBM\n",
      "XGBoost\n",
      "CatBoost\n",
      "\n",
      "Fold 3\n",
      "LigthGBM\n",
      "XGBoost\n",
      "CatBoost\n",
      "\n",
      "Fold 4\n",
      "LigthGBM\n",
      "XGBoost\n",
      "CatBoost\n",
      "\n",
      "Fold 5\n",
      "LigthGBM\n",
      "XGBoost\n",
      "CatBoost\n",
      "\n",
      "LightGBM VAL AUC: 0.8996\n",
      "XGBoost  VAL AUC: 0.8985\n",
      "Catboost VAL AUC: 0.9007\n",
      "Mean Catboost+LightGBM VAL AUC: 0.9005\n",
      "Mean XGBoost+Catboost+LightGBM, VAL AUC: 0.9004\n",
      "\n",
      "Prediction Stage.\n",
      "\n",
      "Load Test Data.\n",
      "\n",
      "Shape of Test Data: (200000, 201)\n",
      "\n",
      "Make predictions...\n",
      "\n",
      "With LightGBM...\n",
      "With XGBoost...\n",
      "With CatBoost...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../input/sample_submission.csv' does not exist: b'../input/sample_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7ab93fa71aaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction Stage.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mprediction_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgb_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nDone.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-d0304b6644cd>\u001b[0m in \u001b[0;36mprediction_stage\u001b[1;34m(df_path, lgb_path, xgb_path, cb_path)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mcb_result\u001b[0m  \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/sample_submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0msubmission\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlgb_result\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mxgb_result\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcb_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xgb_lgb_cb_starter_submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/sample_submission.csv' does not exist: b'../input/sample_submission.csv'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_path = './input/train.csv'\n",
    "    test_path  = './input/test.csv'\n",
    "    \n",
    "    lgb_path = './lgb_models_stack/'\n",
    "    xgb_path = './xgb_models_stack/'\n",
    "    cb_path  = './cb_models_stack/'\n",
    "\n",
    "    #Create dir for models\n",
    "    if not os.path.exists(lgb_path):\n",
    "        os.mkdir(lgb_path)\n",
    "    if not os.path.exists(xgb_path):\n",
    "        os.mkdir(xgb_path)\n",
    "    if not os.path.exists(cb_path):\n",
    "        os.mkdir(cb_path)\n",
    "\n",
    "    print('Train Stage.\\n')\n",
    "    train_stage(train_path, lgb_path, xgb_path, cb_path)\n",
    "    \n",
    "    print('Prediction Stage.\\n')\n",
    "    prediction_stage(test_path, lgb_path, xgb_path, cb_path)\n",
    "    \n",
    "    print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Stage.\n",
      "\n",
      "Load Test Data.\n",
      "\n",
      "Shape of Test Data: (200000, 201)\n",
      "\n",
      "Make predictions...\n",
      "\n",
      "With LightGBM...\n",
      "With XGBoost...\n",
      "With CatBoost...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = './input/train.csv'\n",
    "test_path  = './input/test.csv'\n",
    "\n",
    "lgb_path = './lgb_models_stack/'\n",
    "xgb_path = './xgb_models_stack/'\n",
    "cb_path  = './cb_models_stack/'\n",
    "print('Prediction Stage.\\n')\n",
    "prediction_stage(test_path, lgb_path, xgb_path, cb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('xgb_lgb_cb_starter_submission.csv')\n",
    "sub2 = pd.read_csv('submission_avg_1_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2.target = 0.4*sub1.target + 0.6 * sub2.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2.to_csv('chakchouka.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
